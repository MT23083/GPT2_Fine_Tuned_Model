{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd76691-c637-4884-8c55-5ee73b2f6347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 16:05:57.082129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-20 16:05:57.082177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-20 16:05:57.083570: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-20 16:05:57.090513: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 16:05:57.903874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b3ccd5-45da-488e-91e8-84d8c6742cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# Load the pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad57f86-e0ac-4d43-bd9e-3c8583f14355",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews = pd.read_csv('/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1daafedb-6b40-40b8-af11-0fb7ceb9d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad8769a-2403-469b-91cb-d5da504a6749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7313f-c3d9-4976-afac-15cae1088510",
   "metadata": {},
   "source": [
    "PRE PROCESSING THE SUMMARY AND TEXT COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f819ded3-33aa-438e-b6eb-d6869edb6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the data and dropping irrelevant columns for our study\n",
    "\n",
    "Reviews.drop(columns=['Time','Score','ProfileName','UserId','ProductId','HelpfulnessDenominator','HelpfulnessNumerator'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e9b7342-0e03-4ee1-9680-242292333b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                             Summary  \\\n",
       "0            1               Good Quality Dog Food   \n",
       "1            2                   Not as Advertised   \n",
       "2            3               \"Delight\" says it all   \n",
       "3            4                      Cough Medicine   \n",
       "4            5                         Great taffy   \n",
       "...        ...                                 ...   \n",
       "568449  568450                 Will not do without   \n",
       "568450  568451                        disappointed   \n",
       "568451  568452            Perfect for our maltipoo   \n",
       "568452  568453  Favorite Training and reward treat   \n",
       "568453  568454                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will work with this data from now\n",
    "\n",
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a7ef39-f12b-42f5-b381-d392a4f8d3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary    27\n",
       "Text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total na or null values in both the 'Summary' and 'Text' columns\n",
    "\n",
    "Reviews[['Summary','Text']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82fa2354-3095-4e7e-ad15-6b5b5be59294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the na values with empty string\n",
    "\n",
    "Reviews['Summary'] = Reviews['Summary'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3aa7e4a-05b3-422b-90eb-a9b17512bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id         0\n",
       "Summary    0\n",
       "Text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally we have the concerned data without null values\n",
    "Reviews[['Id','Summary','Text']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f17c65-8447-4c09-b856-2ed4c8061762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173484"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for duplicates \n",
    "Reviews[['Summary','Text']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346c894-5780-457a-b446-3e1885f01ce1",
   "metadata": {},
   "source": [
    "Applying all the Pre-Processing steps for both the 'Summary' and 'Text' columns :\n",
    "\n",
    "1. Removing Duplicate values\n",
    "2. Removing HTML Tags\n",
    "3. Tokenize\n",
    "4. Punctuation Removed\n",
    "5. Stopwords Removed\n",
    "6. Expanding acronyms (if any)\n",
    "7. Stemming\n",
    "8. Lemmatization\n",
    "9. Normalizing the text data by using lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67eb0616-bf06-4fff-870a-dfb1a69cdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/orchid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/orchid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/orchid/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "100%|██████████████████████████████████| 394970/394970 [07:10<00:00, 917.26it/s]\n",
      " 16%|█████▍                            | 63095/394970 [00:11<01:00, 5504.86it/s]/usr/lib/python3/dist-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/B007I7YYGY/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      " 31%|██████████▎                      | 123006/394970 [00:22<00:49, 5509.62it/s]/usr/lib/python3/dist-packages/bs4/__init__.py:337: MarkupResemblesLocatorWarning: \".\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      " 39%|█████████████                    | 155784/394970 [00:28<00:43, 5517.46it/s]/usr/lib/python3/dist-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/B000V9LQ30/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/B001EQ58FQ/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      " 43%|██████████████▎                  | 170672/394970 [00:31<00:40, 5514.40it/s]/usr/lib/python3/dist-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/B000EYOBRU/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████| 394970/394970 [01:11<00:00, 5517.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Remove duplicates\n",
    "Reviews.drop_duplicates(subset=['Text', 'Summary'], inplace=True)\n",
    "\n",
    "# Define function for HTML tag removal\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "acronyms = {\n",
    "    'LOL': 'Laughing Out Loud - Used to indicate laughter or amusement.',\n",
    "    'BRB': 'Be Right Back - Used to indicate that the person will return shortly.',\n",
    "    'OMG': 'Oh My God - Used to express surprise, shock, or amazement.',\n",
    "    'ICYMI': 'In Case You Missed It - Used to bring attention to something that someone may have missed.',\n",
    "    'AMA': 'Ask Me Anything - Used to invite others to ask questions about anything.',\n",
    "    'DM': 'Direct Message - A private message sent on social media platforms or messaging apps.',\n",
    "    'ETA': 'Estimated Time of Arrival - Used to indicate when someone or something is expected to arrive.',\n",
    "    'ETA': 'Edited To Add - Used to indicate that a post has been edited to include additional information.',\n",
    "    'FTW': 'For The Win - Used to express enthusiasm or support for something.',\n",
    "    'FWIW': 'For What It\\'s Worth - Used to preface a statement that may not be very valuable or important.',\n",
    "    'JK': 'Just Kidding - Used to indicate that a previous statement was made in jest or humor.',\n",
    "    'NP': 'No Problem - Used to indicate that something was easily done or accomplished.',\n",
    "    'TY': 'Thank You - Used to express gratitude.',\n",
    "    'YW': 'You\\'re Welcome - Used as a response to \"thank you\" to acknowledge the thanks.',\n",
    "    'GG': 'Good Game - Used to acknowledge the end of a game or competition, often with respect for the opponents.',\n",
    "    'GG': 'Gotta Go - Used to indicate that the person needs to leave or end the conversation.',\n",
    "     'IMO': 'In My Opinion - Used to preface a statement expressing one\\'s personal viewpoint.',\n",
    "    'IMHO': 'In My Humble Opinion - Similar to IMO, used to express a personal opinion with humility.',\n",
    "    'TBH': 'To Be Honest - Used to preface a statement that may be candid or blunt.',\n",
    "    'FYI': 'For Your Information - Used to provide information that may be useful or relevant.',\n",
    "    'BTW': 'By The Way - Used to introduce additional or incidental information.',\n",
    "    'ICYMI': 'In Case You Missed It - Used to bring attention to something that someone may have missed.',\n",
    "    'TMI': 'Too Much Information - Used to indicate that someone has shared more information than necessary or appropriate.',\n",
    "    'IDK': 'I Don\\'t Know - Used to indicate uncertainty or lack of knowledge.',\n",
    "    'AFK': 'Away From Keyboard - Used to indicate that the person is temporarily unavailable.',\n",
    "    'IRL': 'In Real Life - Used to distinguish between online interactions and interactions in the physical world.',\n",
    "    'AMA': 'Ask Me Anything - Used to invite others to ask questions about anything.',\n",
    "    'DM': 'Direct Message - A private message sent on social media platforms or messaging apps.',\n",
    "    'ETA': 'Estimated Time of Arrival - Used to indicate when someone or something is expected to arrive.',\n",
    "    'ETA': 'Edited To Add - Used to indicate that a post has been edited to include additional information.',\n",
    "    'FTW': 'For The Win - Used to express enthusiasm or support for something.',\n",
    "}\n",
    "\n",
    "# Define function for acronym expansion\n",
    "def expand_acronyms(text):\n",
    "    for acronym, expansion in acronyms.items():\n",
    "        text = re.sub(r'\\b' + re.escape(acronym) + r'\\b', expansion, text)\n",
    "    return text\n",
    "\n",
    "# Define function for text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = remove_html_tags(text)\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    # Remove punctuations\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Expand acronyms\n",
    "    text = expand_acronyms(' '.join(words))\n",
    "    # Stemming\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Normalize tokens to lowercase\n",
    "    words = [word.lower() for word in words]\n",
    "    # Join words back into sentence\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply text preprocessing to 'Text' and 'Summary' columns\n",
    "tqdm.pandas()\n",
    "Reviews['Text'] = Reviews['Text'].progress_apply(preprocess_text)\n",
    "Reviews['Summary'] = Reviews['Summary'].progress_apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "717badf0-c68d-4c8c-8450-5b4fa767898e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>good qualiti dog food</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>not advertis</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>delight say</td>\n",
       "      <td>thi confect around centuri it light pillowi ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cough medicin</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>great taffi</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>nice taffi</td>\n",
       "      <td>i got wild hair taffi order five pound bag the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>great just good expens brand</td>\n",
       "      <td>thi saltwat taffi great flavor soft chewi each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>wonder tasti taffi</td>\n",
       "      <td>thi taffi good it soft chewi the flavor amaz i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>yay barley</td>\n",
       "      <td>right i mostli sprout cat eat grass they love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>healthi dog food</td>\n",
       "      <td>thi healthi dog food good digest also good sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>the best hot sauc world</td>\n",
       "      <td>i know cactu tequila uniqu combin ingredi flav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>my cat love diet food better regular food</td>\n",
       "      <td>one boy need lose weight i put food floor chub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>my cat are not fan new food</td>\n",
       "      <td>my cat happili eat felida platinum two year i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>fresh greasi</td>\n",
       "      <td>good flavor came secur pack fresh delici love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>strawberri twizzler yummi</td>\n",
       "      <td>the strawberri twizzler guilti pleasur yummi s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>lot twizzler expect</td>\n",
       "      <td>my daughter love twizzler shipment six pound r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>poor tast</td>\n",
       "      <td>i love eat good watch tv look movi it sweet i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>love</td>\n",
       "      <td>i satisfi twizzler purchas i share other enjoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>great sweet candi</td>\n",
       "      <td>twizzler strawberri childhood favorit candi ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>home deliv twizler</td>\n",
       "      <td>candi deliv fast purchas reason price i home b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>alway fresh</td>\n",
       "      <td>my husband twizzler addict we bought mani time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>twizzler</td>\n",
       "      <td>i bought husband current oversea he love appar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>delici product</td>\n",
       "      <td>i rememb buy candi kid qualiti drop year still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>twizzler</td>\n",
       "      <td>i love candi after weight watcher i cut back s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>plea sell mexico</td>\n",
       "      <td>i live u yr i miss twizzler when i go back vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>twizzler strawberri</td>\n",
       "      <td>product receiv strawberri bag pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>nasti no flavor</td>\n",
       "      <td>the candi red no flavor just plan chewi i woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>great bargain price</td>\n",
       "      <td>i glad amazon carri batteri i hard time find e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>yummi</td>\n",
       "      <td>i got mum diabet need watch sugar intak father...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>great machin</td>\n",
       "      <td>i never huge coffe fan howev mother purchas li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>thi is my tast</td>\n",
       "      <td>thi offer great price great tast thank amazon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>best instant oatmeal</td>\n",
       "      <td>mccann instant oatmeal great must oatmeal scra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>good instant</td>\n",
       "      <td>thi good instant oatmeal best oatmeal brand it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>great irish oatmeal hurri</td>\n",
       "      <td>instant oatmeal becom soggi minut water hit bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>satisfi</td>\n",
       "      <td>mccann instant irish oatmeal varieti pack regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>love gluten free oatmeal</td>\n",
       "      <td>for u celiac diseas product lifesav could bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>oatmeal</td>\n",
       "      <td>what el need know oatmeal instant make half cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>good way to start the day</td>\n",
       "      <td>i wa visit my friend nate the other morn for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>wife favorit breakfast</td>\n",
       "      <td>i order wife reccomend daughter she almost eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>whi would buy oatmeal mcann tast great</td>\n",
       "      <td>the varieti pack tast great i everi morn at ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>oatmeal for oatmeal lover</td>\n",
       "      <td>mccann make oatmeal everi oatmeal connoisseur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td></td>\n",
       "      <td>i mccann oatmeal everi morn order amazon i abl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>good hot breakfast</td>\n",
       "      <td>mccann oatmeal good qualiti choic our favorit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>great tast conveni</td>\n",
       "      <td>we realli like mccann steel cut oat find cook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>hearti oatmeal</td>\n",
       "      <td>thi seem littl wholesom supermarket brand some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>good</td>\n",
       "      <td>good oatmeal i like appl cinnamon best though ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>mushi</td>\n",
       "      <td>the flavor good howev i see differc oaker oat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>veri good next time i wo order varieti pack</td>\n",
       "      <td>i realli like mapl brown sugar flavor the regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>same stuff</td>\n",
       "      <td>thi stuff buy big box store there noth healthi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>do like</td>\n",
       "      <td>thi oatmeal good it mushi soft i like quaker o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                      Summary  \\\n",
       "0    1                        good qualiti dog food   \n",
       "1    2                                 not advertis   \n",
       "2    3                                  delight say   \n",
       "3    4                                cough medicin   \n",
       "4    5                                  great taffi   \n",
       "5    6                                   nice taffi   \n",
       "6    7                 great just good expens brand   \n",
       "7    8                           wonder tasti taffi   \n",
       "8    9                                   yay barley   \n",
       "9   10                             healthi dog food   \n",
       "10  11                      the best hot sauc world   \n",
       "11  12    my cat love diet food better regular food   \n",
       "12  13                  my cat are not fan new food   \n",
       "13  14                                 fresh greasi   \n",
       "14  15                    strawberri twizzler yummi   \n",
       "15  16                          lot twizzler expect   \n",
       "16  17                                    poor tast   \n",
       "17  18                                         love   \n",
       "18  19                            great sweet candi   \n",
       "19  20                           home deliv twizler   \n",
       "20  21                                  alway fresh   \n",
       "21  22                                     twizzler   \n",
       "22  23                               delici product   \n",
       "23  24                                     twizzler   \n",
       "24  25                             plea sell mexico   \n",
       "25  26                          twizzler strawberri   \n",
       "26  27                              nasti no flavor   \n",
       "27  28                          great bargain price   \n",
       "28  29                                        yummi   \n",
       "30  31                                 great machin   \n",
       "31  32                               thi is my tast   \n",
       "32  33                         best instant oatmeal   \n",
       "33  34                                 good instant   \n",
       "34  35                    great irish oatmeal hurri   \n",
       "35  36                                      satisfi   \n",
       "36  37                     love gluten free oatmeal   \n",
       "37  38                                      oatmeal   \n",
       "38  39                    good way to start the day   \n",
       "39  40                       wife favorit breakfast   \n",
       "40  41       whi would buy oatmeal mcann tast great   \n",
       "41  42                    oatmeal for oatmeal lover   \n",
       "42  43                                                \n",
       "43  44                           good hot breakfast   \n",
       "44  45                           great tast conveni   \n",
       "45  46                               hearti oatmeal   \n",
       "46  47                                         good   \n",
       "47  48                                        mushi   \n",
       "48  49  veri good next time i wo order varieti pack   \n",
       "49  50                                   same stuff   \n",
       "50  51                                      do like   \n",
       "\n",
       "                                                 Text  \n",
       "0   i bought sever vital can dog food product foun...  \n",
       "1   product arriv label jumbo salt peanut peanut a...  \n",
       "2   thi confect around centuri it light pillowi ci...  \n",
       "3   if look secret ingredi robitussin i believ i f...  \n",
       "4   great taffi great price there wide assort yumm...  \n",
       "5   i got wild hair taffi order five pound bag the...  \n",
       "6   thi saltwat taffi great flavor soft chewi each...  \n",
       "7   thi taffi good it soft chewi the flavor amaz i...  \n",
       "8   right i mostli sprout cat eat grass they love ...  \n",
       "9   thi healthi dog food good digest also good sma...  \n",
       "10  i know cactu tequila uniqu combin ingredi flav...  \n",
       "11  one boy need lose weight i put food floor chub...  \n",
       "12  my cat happili eat felida platinum two year i ...  \n",
       "13  good flavor came secur pack fresh delici love ...  \n",
       "14  the strawberri twizzler guilti pleasur yummi s...  \n",
       "15  my daughter love twizzler shipment six pound r...  \n",
       "16  i love eat good watch tv look movi it sweet i ...  \n",
       "17  i satisfi twizzler purchas i share other enjoy...  \n",
       "18  twizzler strawberri childhood favorit candi ma...  \n",
       "19  candi deliv fast purchas reason price i home b...  \n",
       "20  my husband twizzler addict we bought mani time...  \n",
       "21  i bought husband current oversea he love appar...  \n",
       "22  i rememb buy candi kid qualiti drop year still...  \n",
       "23  i love candi after weight watcher i cut back s...  \n",
       "24  i live u yr i miss twizzler when i go back vis...  \n",
       "25                 product receiv strawberri bag pack  \n",
       "26  the candi red no flavor just plan chewi i woul...  \n",
       "27  i glad amazon carri batteri i hard time find e...  \n",
       "28  i got mum diabet need watch sugar intak father...  \n",
       "30  i never huge coffe fan howev mother purchas li...  \n",
       "31  thi offer great price great tast thank amazon ...  \n",
       "32  mccann instant oatmeal great must oatmeal scra...  \n",
       "33  thi good instant oatmeal best oatmeal brand it...  \n",
       "34  instant oatmeal becom soggi minut water hit bo...  \n",
       "35  mccann instant irish oatmeal varieti pack regu...  \n",
       "36  for u celiac diseas product lifesav could bett...  \n",
       "37  what el need know oatmeal instant make half cu...  \n",
       "38  i wa visit my friend nate the other morn for c...  \n",
       "39  i order wife reccomend daughter she almost eve...  \n",
       "40  the varieti pack tast great i everi morn at ce...  \n",
       "41  mccann make oatmeal everi oatmeal connoisseur ...  \n",
       "42  i mccann oatmeal everi morn order amazon i abl...  \n",
       "43  mccann oatmeal good qualiti choic our favorit ...  \n",
       "44  we realli like mccann steel cut oat find cook ...  \n",
       "45  thi seem littl wholesom supermarket brand some...  \n",
       "46  good oatmeal i like appl cinnamon best though ...  \n",
       "47  the flavor good howev i see differc oaker oat ...  \n",
       "48  i realli like mapl brown sugar flavor the regu...  \n",
       "49  thi stuff buy big box store there noth healthi...  \n",
       "50  thi oatmeal good it mushi soft i like quaker o...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean and Pre-Processed data\n",
    "\n",
    "Reviews.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a91df3c-f186-4cec-abfc-436ec90ea442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id         0\n",
       "Summary    0\n",
       "Text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab76381d-f40c-4e67-ba7d-f33b06bcdb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews = Reviews[['Text','Summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c23d1f54-6dd1-43fc-a226-5ca438fcb699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "      <td>good qualiti dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>not advertis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thi confect around centuri it light pillowi ci...</td>\n",
       "      <td>delight say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "      <td>cough medicin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "      <td>great taffi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>great sesam chicken good better restur i eaten...</td>\n",
       "      <td>will without</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>i disappoint flavor the chocol note especi wea...</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>these star small give one train session i tri ...</td>\n",
       "      <td>perfect maltipoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>these best treat train reward dog good groom l...</td>\n",
       "      <td>favorit train reward treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>i satisfi product advertis i use cereal raw vi...</td>\n",
       "      <td>great honey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394970 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       i bought sever vital can dog food product foun...   \n",
       "1       product arriv label jumbo salt peanut peanut a...   \n",
       "2       thi confect around centuri it light pillowi ci...   \n",
       "3       if look secret ingredi robitussin i believ i f...   \n",
       "4       great taffi great price there wide assort yumm...   \n",
       "...                                                   ...   \n",
       "568449  great sesam chicken good better restur i eaten...   \n",
       "568450  i disappoint flavor the chocol note especi wea...   \n",
       "568451  these star small give one train session i tri ...   \n",
       "568452  these best treat train reward dog good groom l...   \n",
       "568453  i satisfi product advertis i use cereal raw vi...   \n",
       "\n",
       "                           Summary  \n",
       "0            good qualiti dog food  \n",
       "1                     not advertis  \n",
       "2                      delight say  \n",
       "3                    cough medicin  \n",
       "4                      great taffi  \n",
       "...                            ...  \n",
       "568449                will without  \n",
       "568450                  disappoint  \n",
       "568451            perfect maltipoo  \n",
       "568452  favorit train reward treat  \n",
       "568453                 great honey  \n",
       "\n",
       "[394970 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ac892f4-9655-472b-ba6a-7f3e8cd47aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and preprocessed dataset\n",
    "Reviews.to_csv('/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/processed_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f775c55-16da-4924-b265-ec4e7d9346fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews = pd.read_csv('/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/processed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00e6af3-a37b-4f68-af25-b90f6330fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "Processed_Reviews = Reviews.head(15000)\n",
    "\n",
    "# Divide the Subset into Training and Testing Sets\n",
    "train_df, test_df = train_test_split(Processed_Reviews, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create a Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.iloc[idx]['Text'])  # Convert to string\n",
    "        summary = str(self.data.iloc[idx]['Summary'])  # Convert to string\n",
    "\n",
    "        encoded_text = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=80)\n",
    "        encoded_summary = tokenizer(summary, return_tensors='pt', padding='max_length', truncation=True, max_length=80)\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded_text['input_ids'].squeeze(),\n",
    "            'attention_mask': encoded_text['attention_mask'].squeeze(),\n",
    "            'labels': encoded_summary['input_ids'].squeeze(),\n",
    "            'Summary': summary  # Include the 'Summary' column in the returned dictionary\n",
    "        }\n",
    "\n",
    "# Create instances of the Custom Dataset Class for Training and Testing\n",
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)\n",
    "\n",
    "# Create DataLoaders for Training and Testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example usage of the DataLoader\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    labels = batch['labels']\n",
    "    # Perform training steps using input_ids, attention_mask, and labels\n",
    "\n",
    "# Similarly, you can iterate over test_dataloader for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d312fb3-9d48-4f9b-b2ec-b9d5f0eaa677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.7614301108670506\n",
      "Epoch 2/3, Train Loss: 0.34872168476100673\n",
      "Epoch 3/3, Train Loss: 0.3421756595542485\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "# Set the device for the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the number of epochs\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "# Define the optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define the number of training steps\n",
    "num_training_steps = len(train_dataloader) * NUM_EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_training_steps)\n",
    "\n",
    "# Define the training function\n",
    "def train(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {train_loss}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/fine_tuned_gpt2_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b84e33-8fc5-412a-ba2a-3dc78b351eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.7631358192725615\n",
      "Epoch 2/3, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.34908453074537893\n",
      "Epoch 3/3, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.3423381774601611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.7556755510582165\n",
      "Epoch 2/5, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.34771051770076156\n",
      "Epoch 3/5, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.340826706241139\n",
      "Epoch 4/5, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.33764659583737905\n",
      "Epoch 5/5, Learning Rate: 5e-05, Batch Size: 16, Train Loss: 0.335888842840425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.7593160339377143\n",
      "Epoch 2/3, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.3486774725500833\n",
      "Epoch 3/3, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.34222007322717796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.7592623228715225\n",
      "Epoch 2/5, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.34752416890114546\n",
      "Epoch 3/5, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.34089607148515905\n",
      "Epoch 4/5, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.33737323157997295\n",
      "Epoch 5/5, Learning Rate: 5e-05, Batch Size: 32, Train Loss: 0.3358709277077155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.8697585897858847\n",
      "Epoch 2/3, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.3593686700121246\n",
      "Epoch 3/3, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.34931232657452876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.8675941410897807\n",
      "Epoch 2/5, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.3573299618437886\n",
      "Epoch 3/5, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.3456735009835525\n",
      "Epoch 4/5, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.34201272390782833\n",
      "Epoch 5/5, Learning Rate: 3e-05, Batch Size: 16, Train Loss: 0.3399847836487673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.868223612620072\n",
      "Epoch 2/3, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.35929005863991653\n",
      "Epoch 3/3, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.3494434958662499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.8641600253229792\n",
      "Epoch 2/5, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.3559728608974679\n",
      "Epoch 3/5, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.3455631327392025\n",
      "Epoch 4/5, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.34202333277260716\n",
      "Epoch 5/5, Learning Rate: 3e-05, Batch Size: 32, Train Loss: 0.3402814849449152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 1.1983288670466705\n",
      "Epoch 2/3, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 0.40377729309892113\n",
      "Epoch 3/3, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 0.3852432062002746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 1.1953012144870379\n",
      "Epoch 2/5, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 0.39868673284284095\n",
      "Epoch 3/5, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 0.37440803105180914\n",
      "Epoch 4/5, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 0.36363982722501864\n",
      "Epoch 5/5, Learning Rate: 1e-05, Batch Size: 16, Train Loss: 0.3592761482789435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 1.200513393448835\n",
      "Epoch 2/3, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 0.40409081505442207\n",
      "Epoch 3/3, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 0.38578693179244344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 1.195465607229959\n",
      "Epoch 2/5, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 0.3988317939537493\n",
      "Epoch 3/5, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 0.37440009796145285\n",
      "Epoch 4/5, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 0.3635590917176821\n",
      "Epoch 5/5, Learning Rate: 1e-05, Batch Size: 32, Train Loss: 0.3592039352198216\n"
     ]
    }
   ],
   "source": [
    "# Define the training function\n",
    "'''def train(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "'''\n",
    "# Define the hyperparameters to experiment with\n",
    "learning_rates = [5e-5, 3e-5, 1e-5]  # Example learning rates\n",
    "batch_sizes = [16, 32]  # Example batch sizes\n",
    "num_epochs_list = [3, 5]  # Example number of epochs\n",
    "\n",
    "# Training loop with different hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for epochs in num_epochs_list:\n",
    "            # Load the pre-trained GPT-2 model\n",
    "            model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "\n",
    "            # Define the optimizer and scheduler\n",
    "            optimizer = AdamW(model.parameters(), lr=lr)\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=len(train_dataloader) * epochs)\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(epochs):\n",
    "                train_loss = train(model, train_dataloader, optimizer, scheduler, device)\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Learning Rate: {lr}, Batch Size: {bs}, Train Loss: {train_loss}\")\n",
    "\n",
    "            # Save the fine-tuned model\n",
    "            model.save_pretrained(f\"/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/fine_tuned_gpt2_model_lr_{lr}_bs_{bs}_epochs_{epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9307602-7c7c-4200-aa03-2d3b3db4f971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'Summary'])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over a single batch from the DataLoader\n",
    "for batch in test_dataloader:\n",
    "    # Print the keys of the batch\n",
    "    print(batch.keys())\n",
    "    # Break after printing keys of the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4c31f9-9f89-48e2-80e0-c740eba6e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data <__main__.CustomDataset object at 0x7c8b57508b50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Summaries:   0%|                             | 0/118 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   1%|▏                    | 1/118 [00:00<00:42,  2.76it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   2%|▎                    | 2/118 [00:00<00:38,  3.05it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   3%|▌                    | 3/118 [00:00<00:36,  3.13it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   3%|▋                    | 4/118 [00:01<00:35,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   4%|▉                    | 5/118 [00:01<00:35,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   5%|█                    | 6/118 [00:01<00:34,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   6%|█▏                   | 7/118 [00:02<00:34,  3.23it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   7%|█▍                   | 8/118 [00:02<00:33,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   8%|█▌                   | 9/118 [00:02<00:33,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   8%|█▋                  | 10/118 [00:03<00:33,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:   9%|█▊                  | 11/118 [00:03<00:32,  3.26it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  10%|██                  | 12/118 [00:03<00:32,  3.26it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  11%|██▏                 | 13/118 [00:04<00:32,  3.27it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  12%|██▎                 | 14/118 [00:04<00:31,  3.27it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  13%|██▌                 | 15/118 [00:04<00:31,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  14%|██▋                 | 16/118 [00:04<00:31,  3.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  14%|██▉                 | 17/118 [00:05<00:31,  3.22it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  15%|███                 | 18/118 [00:05<00:31,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  16%|███▏                | 19/118 [00:05<00:31,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  17%|███▍                | 20/118 [00:06<00:30,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  18%|███▌                | 21/118 [00:06<00:30,  3.22it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  19%|███▋                | 22/118 [00:06<00:29,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  19%|███▉                | 23/118 [00:07<00:29,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  20%|████                | 24/118 [00:07<00:29,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  21%|████▏               | 25/118 [00:07<00:29,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  22%|████▍               | 26/118 [00:08<00:28,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  23%|████▌               | 27/118 [00:08<00:28,  3.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  24%|████▋               | 28/118 [00:08<00:28,  3.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  25%|████▉               | 29/118 [00:09<00:27,  3.22it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  25%|█████               | 30/118 [00:09<00:27,  3.23it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  26%|█████▎              | 31/118 [00:09<00:26,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  27%|█████▍              | 32/118 [00:09<00:26,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  28%|█████▌              | 33/118 [00:10<00:26,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  29%|█████▊              | 34/118 [00:10<00:25,  3.26it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  30%|█████▉              | 35/118 [00:10<00:25,  3.26it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  31%|██████              | 36/118 [00:11<00:25,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  31%|██████▎             | 37/118 [00:11<00:25,  3.23it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  32%|██████▍             | 38/118 [00:11<00:24,  3.23it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  33%|██████▌             | 39/118 [00:12<00:24,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  34%|██████▊             | 40/118 [00:12<00:23,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  35%|██████▉             | 41/118 [00:12<00:23,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  36%|███████             | 42/118 [00:13<00:23,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  36%|███████▎            | 43/118 [00:13<00:23,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  37%|███████▍            | 44/118 [00:13<00:22,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  38%|███████▋            | 45/118 [00:13<00:22,  3.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  39%|███████▊            | 46/118 [00:14<00:22,  3.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  40%|███████▉            | 47/118 [00:14<00:22,  3.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  41%|████████▏           | 48/118 [00:14<00:22,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  42%|████████▎           | 49/118 [00:15<00:21,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  42%|████████▍           | 50/118 [00:15<00:21,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  43%|████████▋           | 51/118 [00:15<00:20,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  44%|████████▊           | 52/118 [00:16<00:20,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  45%|████████▉           | 53/118 [00:16<00:20,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  46%|█████████▏          | 54/118 [00:16<00:20,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  47%|█████████▎          | 55/118 [00:17<00:19,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  47%|█████████▍          | 56/118 [00:17<00:19,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  48%|█████████▋          | 57/118 [00:17<00:19,  3.13it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  49%|█████████▊          | 58/118 [00:18<00:19,  3.12it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  50%|██████████          | 59/118 [00:18<00:18,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  51%|██████████▏         | 60/118 [00:18<00:18,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  52%|██████████▎         | 61/118 [00:19<00:17,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  53%|██████████▌         | 62/118 [00:19<00:17,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  53%|██████████▋         | 63/118 [00:19<00:17,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  54%|██████████▊         | 64/118 [00:19<00:16,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  55%|███████████         | 65/118 [00:20<00:16,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  56%|███████████▏        | 66/118 [00:20<00:16,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  57%|███████████▎        | 67/118 [00:20<00:16,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  58%|███████████▌        | 68/118 [00:21<00:15,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  58%|███████████▋        | 69/118 [00:21<00:15,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  59%|███████████▊        | 70/118 [00:21<00:15,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  60%|████████████        | 71/118 [00:22<00:14,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  61%|████████████▏       | 72/118 [00:22<00:14,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  62%|████████████▎       | 73/118 [00:22<00:14,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  63%|████████████▌       | 74/118 [00:23<00:13,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  64%|████████████▋       | 75/118 [00:23<00:13,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  64%|████████████▉       | 76/118 [00:23<00:13,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  65%|█████████████       | 77/118 [00:24<00:12,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  66%|█████████████▏      | 78/118 [00:24<00:12,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  67%|█████████████▍      | 79/118 [00:24<00:12,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  68%|█████████████▌      | 80/118 [00:24<00:11,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  69%|█████████████▋      | 81/118 [00:25<00:11,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  69%|█████████████▉      | 82/118 [00:25<00:11,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  70%|██████████████      | 83/118 [00:25<00:11,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  71%|██████████████▏     | 84/118 [00:26<00:10,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  72%|██████████████▍     | 85/118 [00:26<00:10,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  73%|██████████████▌     | 86/118 [00:26<00:10,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  74%|██████████████▋     | 87/118 [00:27<00:09,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  75%|██████████████▉     | 88/118 [00:27<00:09,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  75%|███████████████     | 89/118 [00:27<00:09,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  76%|███████████████▎    | 90/118 [00:28<00:08,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  77%|███████████████▍    | 91/118 [00:28<00:08,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  78%|███████████████▌    | 92/118 [00:28<00:08,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  79%|███████████████▊    | 93/118 [00:29<00:07,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  80%|███████████████▉    | 94/118 [00:29<00:07,  3.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  81%|████████████████    | 95/118 [00:29<00:07,  3.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  81%|████████████████▎   | 96/118 [00:30<00:07,  3.14it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  82%|████████████████▍   | 97/118 [00:30<00:06,  3.13it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  83%|████████████████▌   | 98/118 [00:30<00:06,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  84%|████████████████▊   | 99/118 [00:30<00:06,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  85%|████████████████   | 100/118 [00:31<00:05,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  86%|████████████████▎  | 101/118 [00:31<00:05,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  86%|████████████████▍  | 102/118 [00:31<00:05,  3.12it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  87%|████████████████▌  | 103/118 [00:32<00:04,  3.14it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  88%|████████████████▋  | 104/118 [00:32<00:04,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  89%|████████████████▉  | 105/118 [00:32<00:04,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  90%|█████████████████  | 106/118 [00:33<00:03,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  91%|█████████████████▏ | 107/118 [00:33<00:03,  3.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  92%|█████████████████▍ | 108/118 [00:33<00:03,  3.11it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  92%|█████████████████▌ | 109/118 [00:34<00:02,  3.14it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  93%|█████████████████▋ | 110/118 [00:34<00:02,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  94%|█████████████████▊ | 111/118 [00:34<00:02,  3.14it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  95%|██████████████████ | 112/118 [00:35<00:01,  3.12it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  96%|██████████████████▏| 113/118 [00:35<00:01,  3.13it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  97%|██████████████████▎| 114/118 [00:35<00:01,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  97%|██████████████████▌| 115/118 [00:36<00:00,  3.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  98%|██████████████████▋| 116/118 [00:36<00:00,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries:  99%|██████████████████▊| 117/118 [00:36<00:00,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Generating Summaries: 100%|███████████████████| 118/118 [00:36<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "{'rouge-1': {'r': 0.43619882487882433, 'p': 0.056787406295847054, 'f': 0.09652970097920145}, 'rouge-2': {'r': 0.12342678506678481, 'p': 0.012133117663315379, 'f': 0.021025393913372086}, 'rouge-l': {'r': 0.40230660450660466, 'p': 0.052011204349104036, 'f': 0.08846398662736299}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from rouge import Rouge\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the saved fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/fine_tuned_gpt2_model/\")\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/fine_tuned_gpt2_model/\")\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "# Set the device for the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define a function to generate summaries from the model\n",
    "def generate_summaries(model, tokenizer, dataloader, device):\n",
    "    summaries = []\n",
    "    references = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating Summaries\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            # Generate summaries\n",
    "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=100, num_beams=4, early_stopping=True)\n",
    "\n",
    "            # Decode generated summaries\n",
    "            decoded_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            summaries.extend(decoded_summaries)\n",
    "\n",
    "            # Get the references (actual summaries)\n",
    "            references.extend([str(summary) for summary in batch['Summary']])\n",
    "\n",
    "    return summaries, references\n",
    "\n",
    "# Load the test dataset and create a DataLoader\n",
    "test_dataset = CustomDataset(test_df)\n",
    "print(\"Test Data\",test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Generate summaries for the test set\n",
    "predicted_summaries, actual_summaries = generate_summaries(model, tokenizer, test_dataloader, device)\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(predicted_summaries, actual_summaries, avg=True)\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(\"ROUGE Scores:\")\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9660df-c6d6-40f5-b96a-45f159006db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "ROUGE-1: Precision: 0.06, Recall: 0.44, F1-Score: 0.10\n",
      "ROUGE-2: Precision: 0.01, Recall: 0.12, F1-Score: 0.02\n",
      "ROUGE-L: Precision: 0.05, Recall: 0.40, F1-Score: 0.09\n"
     ]
    }
   ],
   "source": [
    "print(\"ROUGE Scores:\")\n",
    "for metric, values in scores.items():\n",
    "    precision = values['p']\n",
    "    recall = values['r']\n",
    "    f1_score = values['f']\n",
    "    print(f\"{metric.upper()}: Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14e8b7d5-25e1-4b3f-8dbd-515e4be41de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: I have been drinking this tea for a long time now.  I used to have to purchase it at a doctor's office because it wasn't available elsewhere. I'm so glad that I can buy it now from Amazon.com.  I drink this tea throughout the day like other folks drink coffee.  Wonderful taste.\n"
     ]
    }
   ],
   "source": [
    "# Input text\n",
    "input_text = \"I have been drinking this tea for a long time now.  \\\n",
    "I used to have to purchase it at a doctor's office because it wasn't available elsewhere. \\\n",
    "I'm so glad that I can buy it now from Amazon.com.  I drink this tea throughout the day like other folks drink coffee.  Wonderful taste.\"\n",
    "\n",
    "# Tokenize and preprocess the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate summary\n",
    "generated_summary = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "decoded_summary = tokenizer.decode(generated_summary[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Summary:\", decoded_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b488650d-8ba9-433d-afda-7e23337091d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_review = pd.read_csv('/home/orchid/Documents/HumourDetection/Sarthak_Sharma/IR_ASSIGNMENT_4/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95a76ea4-5fe7-4fd3-a04c-08867d0ac928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have been drinking this tea for a long time now.  I used to have to purchase it at a doctor's office because it wasn't available elsewhere.  I'm so glad that I can buy it now from Amazon.com.  I drink this tea throughout the day like other folks drink coffee.  Wonderful taste.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_review['Text'][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db8bcb-d12b-45f9-8a49-677594824547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
